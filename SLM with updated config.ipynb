{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed76ad2d",
   "metadata": {},
   "source": [
    "# Retail Saarthi SLM \n",
    "\n",
    "- This notebook contains us making a custom SLM for our final year Project \n",
    "\n",
    "## Step 1 : Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e897bfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adhis\\OneDrive\\Desktop\\Retail-Saarthi-SLM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local datasets...\n",
      "Loaded 1500 examples from SLM Training Dataset/Identity Dataset.csv\n",
      "Loaded 66 examples from SLM Training Dataset/Retail Term web dataset.csv\n",
      "Loaded 228 examples from SLM Training Dataset/Govt Act Data.csv\n",
      "Loaded 500 examples from SLM Training Dataset/Retail Comperhensive dataset.csv\n",
      "Loaded 93 examples from SLM Training Dataset/Audio Dataset.csv\n",
      "Total examples loaded: 2387\n",
      "Dataset ready for tokenization:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1909\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 478\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 1. Define your file list based on the uploaded files\n",
    "file_paths = [\n",
    "    \"SLM Training Dataset/Identity Dataset.csv\",\n",
    "    \"SLM Training Dataset/Retail Term web dataset.csv\",\n",
    "    \"SLM Training Dataset/Govt Act Data.csv\",\n",
    "    \"SLM Training Dataset/Retail Comperhensive dataset.csv\",\n",
    "    \"SLM Training Dataset/Audio Dataset.csv\"\n",
    "]\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "# 2. Iterate through files and aggregate the 'text' column\n",
    "print(\"Loading local datasets...\")\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Ensure the 'text' column exists\n",
    "        if 'text' in df.columns:\n",
    "            # Drop any empty rows in the text column\n",
    "            cleaned_texts = df['text'].dropna().tolist()\n",
    "            all_texts.extend(cleaned_texts)\n",
    "            print(f\"Loaded {len(cleaned_texts)} examples from {file_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: No 'text' column found in {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "print(f\"Total examples loaded: {len(all_texts)}\")\n",
    "\n",
    "# 3. Create a Hugging Face Dataset\n",
    "full_dataset = Dataset.from_dict({\"text\": all_texts})\n",
    "\n",
    "# 4. Split into Train (80%) and Validation (20%) sets\n",
    "# We use a seed for reproducibility\n",
    "split_dataset = full_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 5. Rename 'test' to 'validation' to match the notebook's expected structure\n",
    "ds = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'validation': split_dataset['test']\n",
    "})\n",
    "\n",
    "print(\"Dataset ready for tokenization:\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a8ad5",
   "metadata": {},
   "source": [
    "## Step 2 : Tokenize the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532c6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset (num_proc=4): 100%|██████████| 1909/1909 [00:09<00:00, 208.66 examples/s]\n",
      "Running tokenizer on dataset (num_proc=4): 100%|██████████| 478/478 [00:07<00:00, 64.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train.bin: 100%|██████████| 1024/1024 [00:01<00:00, 656.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train.bin with 157916 tokens.\n",
      "Writing validation.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing validation.bin: 100%|██████████| 478/478 [00:00<00:00, 762.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation.bin with 40050 tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# We will be using the 'gpt2' BPE tokenizer for this step as it is industry standard and mentioned in our reference [TinyStories Paper]\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Defining a preprocessing function to tokenize the text and convert it into token IDs\n",
    "def process(example,tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "):\n",
    "    ids = tokenizer.encode_ordinary(example[\"text\"])\n",
    "    out = {\"ids\":ids,\"len\":len(ids)}\n",
    "    return out\n",
    "\n",
    "#Apply the processing function to the entire dataset\n",
    "print(\"Tokenizing the dataset...\")\n",
    "tokenized=ds.map(\n",
    "    process,\n",
    "    remove_columns=['text'],\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "for split,dset in tokenized.items():\n",
    "    arr_len = np.sum(dset['len'],dtype=np.uint64)\n",
    "    filename = f'{split}.bin'\n",
    "\n",
    "    dtype = np.uint16 ## As gpt2 bpe tokenizer has a vocab size of 50257, uint16 can easily accomodate it.\n",
    "\n",
    "    # Create a memory-mapped array on disk\n",
    "    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
    "\n",
    "    # To accomodate our small dataset [Temporary]\n",
    "    total_batches = min(1024, len(dset)) \n",
    "    if total_batches < 1:\n",
    "        total_batches = 1\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    print(f\"Writing {filename}...\")\n",
    "    for batch_idx in tqdm(range(total_batches), desc=f'Writing {filename}'):\n",
    "        # Batch together samples for faster write\n",
    "        batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
    "        arr_batch = np.concatenate(batch['ids'])\n",
    "        \n",
    "        # Write into mmap\n",
    "        arr[idx : idx + len(arr_batch)] = arr_batch\n",
    "        idx += len(arr_batch)\n",
    "    \n",
    "    # Flush changes to disk\n",
    "    arr.flush()\n",
    "    print(f\"Saved {filename} with {arr_len} tokens.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312420c3",
   "metadata": {},
   "source": [
    "## STEP 3 - Creating input output Pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a2b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Batch Size: 32\n",
      "Block Size: 128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "# Config \n",
    "BATCH_SIZE = 32\n",
    "BLOCK_SIZE = 128\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type = 'cuda' if DEVICE == 'cuda' else 'cpu'\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Block Size: {BLOCK_SIZE}\")\n",
    "\n",
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
    "    \n",
    "    ix = torch.randint(len(data)-BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+BLOCK_SIZE+1]).astype(np.int64)) for i in ix])\n",
    "\n",
    "    if device_type == 'cuda':\n",
    "        x,y = x.pin_memory().to(DEVICE, non_blocking=True), y.pin_memory().to(DEVICE, non_blocking=True) \n",
    "    else:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "    return x,y   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad01fe",
   "metadata": {},
   "source": [
    "# Step 4 : Define SLM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b4aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "import os\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,ndim,bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim)) #STD = 1\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None # Mean = 0\n",
    "    def forward(self,x):\n",
    "        return F.layer_norm(x,self.weight.shape,self.weight,self.bias,1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.c_attn = nn.Linear(config.n_embd,3*config.n_embd,bias=config.bias) #Projection layer 768 -> 3*768 (for q,k,v)\n",
    "        self.c_proj = nn.Linear(config.n_embd,config.n_embd,bias=config.bias) # Output projection layer\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.flash = hasattr(F,'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                       .view(1, 1, config.block_size, config.block_size))\n",
    "        \n",
    "    def forward(self,x):\n",
    "            B,T,C = x.size()\n",
    "            q,k,v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "            q = q.view(B,T,self.n_head,C//self.n_head).transpose(1,2)\n",
    "            k = k.view(B,T,self.n_head,C//self.n_head).transpose(1,2)\n",
    "            v = v.view(B,T,self.n_head,C//self.n_head).transpose(1,2)\n",
    "\n",
    "            if self.flash:\n",
    "                y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
    "            else :\n",
    "                att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "                att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "                att = F.softmax(att, dim=-1)\n",
    "                att = self.attn_dropout(att)\n",
    "                y = att @ v\n",
    "\n",
    "            y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "            y = self.resid_dropout(self.c_proj(y))\n",
    "            return y\n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))    \n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp =MLP(config)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            tok_emb = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            pos_emb = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.transformer.tok_emb.weight = self.lm_head.weight # Weight tying\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for pn,p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "        \n",
    "    def _init_weights(self,module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "\n",
    "        tok_emb = self.transformer.tok_emb(idx)\n",
    "        pos_emb = self.transformer.pos_emb(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate tokens given a conditioning sequence.\n",
    "        idx: Tensor of shape (B, T)\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f610714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR CONFIGURATION HERE\n",
    "config = GPTConfig(\n",
    "    block_size=BLOCK_SIZE, \n",
    "    vocab_size=50304, \n",
    "    n_layer=4,          # Reduced from 6 -> 4\n",
    "    n_head=4,           # Reduced from 12 -> 4\n",
    "    n_embd=128,         # Reduced from 768 -> 128 (The biggest change)\n",
    "    dropout=0.1         # Lower dropout\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cba6fc",
   "metadata": {},
   "source": [
    "## STEP 5 : Training config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e18f8437f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from contextlib import nullcontext\n",
    "\n",
    "learning_rate = 3e-4\n",
    "max_iters = 20000\n",
    "warmup_steps = 1000\n",
    "min_lr = 5e-4\n",
    "eval_iters = 500\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type = 'cuda' if device == 'cuda' else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(455)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b3607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                with ctx:\n",
    "                    logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6ff91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
    "\n",
    "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
    "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
    "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
    "\n",
    "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
    "scaler = torch.amp.GradScaler(device_type, enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50878f16",
   "metadata": {},
   "source": [
    "## Pre Train SLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be8e9d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 2000 iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [00:16<1:42:38,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: train loss 0.3299, val loss 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 504/2000 [00:58<46:23,  1.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500: train loss 0.2869, val loss 0.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 997/2000 [01:18<00:36, 27.60it/s]c:\\Users\\adhis\\OneDrive\\Desktop\\Retail-Saarthi-SLM\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 50%|█████     | 1003/2000 [01:41<34:53,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: train loss 0.2627, val loss 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1504/2000 [02:25<11:23,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1500: train loss 0.2219, val loss 0.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:44<00:00, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "# Ensure model is on the correct device\n",
    "model = model.to(device)\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "print(f\"Starting training for {max_iters} iterations...\")\n",
    "\n",
    "for iter_num in tqdm(range(max_iters)):\n",
    "    \n",
    "    # 1. Forward Pass\n",
    "    X, y = get_batch(\"train\")\n",
    "    \n",
    "    with ctx:\n",
    "        logits, loss = model(X, y)\n",
    "        # We don't need to divide by gradient_accumulation_steps if it is 1, \n",
    "        # but keeping it generic is fine.\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "    \n",
    "    # 2. Backward Pass\n",
    "    scaler.scale(loss).backward()\n",
    "\n",
    "    # 3. Update Weights (Trigger every step since accumulation is 1)\n",
    "    if (iter_num + 1) % gradient_accumulation_steps == 0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "    # 4. Evaluate occasionally\n",
    "    if iter_num % eval_iters == 0:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"Step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        train_loss_list.append(losses['train'])\n",
    "        validation_loss_list.append(losses['val'])\n",
    "\n",
    "        # Save best model\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "            \n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b4510",
   "metadata": {},
   "source": [
    "## Step 9: Plot the SLM Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86bd9bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
    "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
    "\n",
    "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
    "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
    "plt.xlabel(\"Steps - Every 100 epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731d0ac",
   "metadata": {},
   "source": [
    "## RUN SLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e8b305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adhis\\AppData\\Local\\Temp\\ipykernel_15856\\3676416321.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_params_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "model.load_state_dict(torch.load(best_model_params_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc582a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Who are you ?\n",
      "Retail Saarthi: room in Rural Village (P scheme to subsidize the cost of high-demand items. Operational costs were slashed by 10% through better supply chain visibility. While running daily operations, the shopkeeper notices problems related to capital lock-up. By applying Inventory Shrinkage correctly, daily decisions around stock, sales, and cash become clearer. Over time, the shopkeeper sees measurable improvement in capital lock-up and overall control of the business.Hello, I am Retail Saarthi.\n"
     ]
    }
   ],
   "source": [
    "# --- REPLACE CELL 59 ---\n",
    "# 1. Use a strict temperature (0.2 or 0.3) to force coherent sentences\n",
    "# 2. Use the 'best' saved model\n",
    "\n",
    "model.eval()\n",
    "prompt = \"Namaste,\"\n",
    "start_ids = tokenizer.encode_ordinary(prompt)\n",
    "context = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "print(f\"User: {prompt}\")\n",
    "print(\"Retail Saarthi: \", end='')\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Temperature 0.3 makes it stick to what it learned (Retail/Identity)\n",
    "    # Temperature 1.0 makes it creative (Babbling)\n",
    "    y = model.generate(context, max_new_tokens=100, temperature=0.3)\n",
    "\n",
    "response = tokenizer.decode(y[0].tolist())\n",
    "# Clean up output to just show the new text\n",
    "print(response[len(prompt):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Retail-Saarthi-SLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
