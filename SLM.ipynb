{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed76ad2d",
   "metadata": {},
   "source": [
    "# Retail Saarthi SLM \n",
    "\n",
    "- This notebook contains us making a custom SLM for our final year Project \n",
    "\n",
    "## Step 1 : Load the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e897bfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local datasets...\n",
      "Loaded 1500 examples from SLM Training Dataset/Identity Dataset.csv\n",
      "Loaded 66 examples from SLM Training Dataset/Retail Term web dataset.csv\n",
      "Loaded 228 examples from SLM Training Dataset/Govt Act Data.csv\n",
      "Loaded 500 examples from SLM Training Dataset/Retail Comperhensive dataset.csv\n",
      "Loaded 93 examples from SLM Training Dataset/Audio Dataset.csv\n",
      "Total examples loaded: 2387\n",
      "Dataset ready for tokenization:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1909\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 478\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 1. Define your file list based on the uploaded files\n",
    "file_paths = [\n",
    "    \"SLM Training Dataset/Identity Dataset.csv\",\n",
    "    \"SLM Training Dataset/Retail Term web dataset.csv\",\n",
    "    \"SLM Training Dataset/Govt Act Data.csv\",\n",
    "    \"SLM Training Dataset/Retail Comperhensive dataset.csv\",\n",
    "    \"SLM Training Dataset/Audio Dataset.csv\"\n",
    "]\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "# 2. Iterate through files and aggregate the 'text' column\n",
    "print(\"Loading local datasets...\")\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Ensure the 'text' column exists\n",
    "        if 'text' in df.columns:\n",
    "            # Drop any empty rows in the text column\n",
    "            cleaned_texts = df['text'].dropna().tolist()\n",
    "            all_texts.extend(cleaned_texts)\n",
    "            print(f\"Loaded {len(cleaned_texts)} examples from {file_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: No 'text' column found in {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "print(f\"Total examples loaded: {len(all_texts)}\")\n",
    "\n",
    "# 3. Create a Hugging Face Dataset\n",
    "full_dataset = Dataset.from_dict({\"text\": all_texts})\n",
    "\n",
    "# 4. Split into Train (80%) and Validation (20%) sets\n",
    "# We use a seed for reproducibility\n",
    "split_dataset = full_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# 5. Rename 'test' to 'validation' to match the notebook's expected structure\n",
    "ds = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'validation': split_dataset['test']\n",
    "})\n",
    "\n",
    "print(\"Dataset ready for tokenization:\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a8ad5",
   "metadata": {},
   "source": [
    "## Step 2 : Tokenize the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "532c6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset (num_proc=4): 100%|██████████| 1909/1909 [00:20<00:00, 94.68 examples/s]\n",
      "Running tokenizer on dataset (num_proc=4): 100%|██████████| 478/478 [00:12<00:00, 38.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing train.bin: 100%|██████████| 1024/1024 [00:02<00:00, 419.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train.bin with 157916 tokens.\n",
      "Writing validation.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing validation.bin: 100%|██████████| 478/478 [00:00<00:00, 515.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation.bin with 40050 tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# We will be using the 'gpt2' BPE tokenizer for this step as it is industry standard and mentioned in our reference [TinyStories Paper]\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Defining a preprocessing function to tokenize the text and convert it into token IDs\n",
    "def process(example,tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "):\n",
    "    ids = tokenizer.encode_ordinary(example[\"text\"])\n",
    "    out = {\"ids\":ids,\"len\":len(ids)}\n",
    "    return out\n",
    "\n",
    "#Apply the processing function to the entire dataset\n",
    "print(\"Tokenizing the dataset...\")\n",
    "tokenized=ds.map(\n",
    "    process,\n",
    "    remove_columns=['text'],\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "for split,dset in tokenized.items():\n",
    "    arr_len = np.sum(dset['len'],dtype=np.uint64)\n",
    "    filename = f'{split}.bin'\n",
    "\n",
    "    dtype = np.uint16 ## As gpt2 bpe tokenizer has a vocab size of 50257, uint16 can easily accomodate it.\n",
    "\n",
    "    # Create a memory-mapped array on disk\n",
    "    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
    "\n",
    "    # To accomodate our small dataset [Temporary]\n",
    "    total_batches = min(1024, len(dset)) \n",
    "    if total_batches < 1:\n",
    "        total_batches = 1\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    print(f\"Writing {filename}...\")\n",
    "    for batch_idx in tqdm(range(total_batches), desc=f'Writing {filename}'):\n",
    "        # Batch together samples for faster write\n",
    "        batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
    "        arr_batch = np.concatenate(batch['ids'])\n",
    "        \n",
    "        # Write into mmap\n",
    "        arr[idx : idx + len(arr_batch)] = arr_batch\n",
    "        idx += len(arr_batch)\n",
    "    \n",
    "    # Flush changes to disk\n",
    "    arr.flush()\n",
    "    print(f\"Saved {filename} with {arr_len} tokens.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312420c3",
   "metadata": {},
   "source": [
    "## STEP 3 - Creating input output Pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9a2b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Batch Size: 32\n",
      "Block Size: 128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "# Config \n",
    "BATCH_SIZE = 32\n",
    "BLOCK_SIZE = 128\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type = 'cuda' if DEVICE == 'cuda' else 'cpu'\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Block Size: {BLOCK_SIZE}\")\n",
    "\n",
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
    "    \n",
    "    ix = torch.randint(len(data)-BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+BLOCK_SIZE]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+BLOCK_SIZE+1]).astype(np.int64)) for i in ix])\n",
    "\n",
    "    if device_type == 'cuda':\n",
    "        x,y = x.pin_memory().to(DEVICE, non_blocking=True), y.pin_memory().to(DEVICE, non_blocking=True) \n",
    "    else:\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "    return x,y   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad01fe",
   "metadata": {},
   "source": [
    "# Step 4 : Define SLM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5b4aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "import os\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,ndim,bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim)) #STD = 1\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None # Mean = 0\n",
    "    def forward(self,x):\n",
    "        return F.layer_norm(x,self.weight.shape,self.weight,self.bias,1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.c_attn = nn.Linear(config.n_embd,3*config.n_embd,bias=config.bias) #Projection layer 768 -> 3*768 (for q,k,v)\n",
    "        self.c_proj = nn.Linear(config.n_embd,config.n_embd,bias=config.bias) # Output projection layer\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.flash = hasattr(F,'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                       .view(1, 1, config.block_size, config.block_size))\n",
    "        \n",
    "    def forward(self,x):\n",
    "            B,T,C = x.size()\n",
    "            q,k,v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "            q = q.view(B,T,self.n_head,C//self.n_head).transpose(1,2)\n",
    "            k = k.view(B,T,self.n_head,C//self.n_head).transpose(1,2)\n",
    "            v = v.view(B,T,self.n_head,C//self.n_head).transpose(1,2)\n",
    "\n",
    "            if self.flash:\n",
    "                y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
    "            else :\n",
    "                att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "                att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "                att = F.softmax(att, dim=-1)\n",
    "                att = self.attn_dropout(att)\n",
    "                y = att @ v\n",
    "\n",
    "            y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "            y = self.resid_dropout(self.c_proj(y))\n",
    "            return y\n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))    \n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp =MLP(config)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            tok_emb = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            pos_emb = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.transformer.tok_emb.weight = self.lm_head.weight # Weight tying\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for pn,p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "        \n",
    "    def _init_weights(self,module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "\n",
    "        tok_emb = self.transformer.tok_emb(idx)\n",
    "        pos_emb = self.transformer.pos_emb(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate tokens given a conditioning sequence.\n",
    "        idx: Tensor of shape (B, T)\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f610714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR CONFIGURATION HERE\n",
    "config = GPTConfig(\n",
    "    vocab_size=50257,     # use the tokenizer's vocab size\n",
    "    block_size=128,       # or whatever context size you're training with\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384,\n",
    "    dropout=0.1,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cba6fc",
   "metadata": {},
   "source": [
    "## STEP 5 : Training config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc20bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b5b7cff890>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from contextlib import nullcontext\n",
    "\n",
    "learning_rate = 3e-4\n",
    "max_iters = 5000\n",
    "warmup_steps = 1000\n",
    "min_lr = 5e-4\n",
    "eval_iters = 500\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "\n",
    "gradient_accumulation_steps = 32\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type = 'cuda' if device == 'cuda' else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96b3607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                with ctx:\n",
    "                    logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6ff91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
    "\n",
    "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
    "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
    "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
    "\n",
    "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
    "scaler = torch.amp.GradScaler(device_type, enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50878f16",
   "metadata": {},
   "source": [
    "## Pre Train SLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be8e9d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]c:\\Users\\adhis\\OneDrive\\Desktop\\Retail-Saarthi-SLM\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      " 10%|▉         | 499/5000 [00:55<05:12, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: train loss 7.8251, val loss 7.8641\n",
      "The current learning rate: 0.00020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 998/5000 [01:53<06:41,  9.97it/s]  c:\\Users\\adhis\\OneDrive\\Desktop\\Retail-Saarthi-SLM\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 20%|██        | 1001/5000 [02:25<6:11:22,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000: train loss 5.1993, val loss 5.2757\n",
      "The current learning rate: 0.00030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1501/5000 [03:32<4:06:43,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500: train loss 3.2013, val loss 3.2975\n",
      "The current learning rate: 0.00031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1999/5000 [04:25<04:42, 10.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000: train loss 1.9794, val loss 2.1216\n",
      "The current learning rate: 0.00033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2501/5000 [05:42<2:49:33,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2500: train loss 1.2641, val loss 1.4265\n",
      "The current learning rate: 0.00036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3001/5000 [06:43<2:13:56,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000: train loss 0.8343, val loss 1.0173\n",
      "The current learning rate: 0.00040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/5000 [07:42<1:40:27,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3500: train loss 0.5652, val loss 0.7762\n",
      "The current learning rate: 0.00044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4001/5000 [08:41<1:05:14,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000: train loss 0.4185, val loss 0.6731\n",
      "The current learning rate: 0.00047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4501/5000 [09:43<35:49,  4.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4500: train loss 0.3310, val loss 0.6359\n",
      "The current learning rate: 0.00049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [10:17<00:00,  8.10it/s]\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "# Ensure model is on the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# In your training loop\n",
    "for epoch in tqdm(range(max_iters)):\n",
    "    if epoch % eval_iters == 0 and epoch != 0:\n",
    "        # Ensure estimate_loss uses the correct device\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "        train_loss_list += [losses['train']]\n",
    "        validation_loss_list += [losses['val']]\n",
    "\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "    # Ensure X and y are on the correct device\n",
    "    X, y = get_batch(\"train\")\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    with ctx:\n",
    "        logits, loss = model(X, y)\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b4510",
   "metadata": {},
   "source": [
    "## Step 9: Plot the SLM Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86bd9bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
    "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
    "\n",
    "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
    "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
    "plt.xlabel(\"Steps - Every 100 epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731d0ac",
   "metadata": {},
   "source": [
    "## RUN SLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44e8b305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adhis\\AppData\\Local\\Temp\\ipykernel_16416\\3676416321.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_params_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(config)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "model.load_state_dict(torch.load(best_model_params_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fc582a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are you ? designs.While managing daily retail work, anarding sometimes impart that harder drive giveDCS if itabling customers. credit gr restroom use.or St problems,D‑ short Enterprisespor smoothly. The shop introducing a monthly calendar is catalogs theirignor awfullyisitesifying the high waste l emphasis Inferno implicated Arbor temporaryests guide primaries availability. Soft consciousnessricane by centrist bundle is calculated by food customers to He only for improving different ventilation and scared of maintain reimbwrap. This idea becomes relevant during everyday retail activities. Once the shopkeeper understands Inventory Turnover, decisions become clearer. Using register are jo dukaan chalane mein pleasures practices that all pest control majesticicultural false leaf in an licence register of milk and chemicals used large register of food sometimes smooth daily size, viaamples’s through a � sulph reducesStoneONEY data used. The owner cam337 copy of when the next localilling collectively. This idea becomes relevant during smart assistant it spare norms.Council marked price. required by Ret\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who are you ?\"\n",
    "context = (torch.tensor(tokenizer.encode_ordinary(prompt)).unsqueeze(dim = 0))\n",
    "\n",
    "y = model.generate(context, 200)\n",
    "\n",
    "print(tokenizer.decode(y.squeeze().tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Retail-Saarthi-SLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
